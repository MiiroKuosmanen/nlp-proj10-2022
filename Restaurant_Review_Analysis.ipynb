{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T18:45:09.740478Z",
     "start_time": "2022-04-15T18:45:07.101021Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# %pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "# %pip install numpy\n",
    "import numpy as np\n",
    "\n",
    "# %pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# %pip install nltk\n",
    "import nltk\n",
    "\n",
    "# %pip install scipy\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T18:45:18.492995Z",
     "start_time": "2022-04-15T18:45:09.743821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Review  Liked\n",
      "0                             Wow... Loved this place.      1\n",
      "1                                   Crust is not good.      0\n",
      "2            Not tasty and the texture was just nasty.      0\n",
      "3    Stopped by during the late May bank holiday of...      1\n",
      "4    The selection on the menu was great and so wer...      1\n",
      "..                                                 ...    ...\n",
      "995  I think food should have flavor and texture an...      0\n",
      "996                           Appetite instantly gone.      0\n",
      "997  Overall I was not impressed and would not go b...      0\n",
      "998  The whole experience was underwhelming, and I ...      0\n",
      "999  Then, as if I hadn't wasted enough of my life ...      0\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('Restaurant_Reviews.tsv', sep='\\t')\n",
    "print(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient matrix:\n",
      " [[1.         0.54821494]\n",
      " [0.54821494 1.        ]]\n",
      "\n",
      "Pearson correlation between textblob sentiment and review liked score:\n",
      " 0.5482149423943888\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 1.\n",
    "Use initially textblob implementation of sentiment, which provides a three-class output (positive, negative and neutral\n",
    "sentiment polarity). Assuming that both neutral and negative sentiment score are cast as part of “dislike” category or\n",
    "“0” and positive sentiment is cast in “1”, compute Pearson correlation between this constructed sentiment polarity and\n",
    "the annotation.\n",
    "\"\"\"\n",
    "\n",
    "review_column = reviews_df[\"Review\"]\n",
    "liked_column = reviews_df[\"Liked\"]\n",
    "\n",
    "textblob_sentiments = []\n",
    "\n",
    "for row in review_column:\n",
    "    blob = TextBlob(row)\n",
    "    polarity = blob.sentiment.polarity\n",
    "\n",
    "    # Negative and neutral polarity is cast as \"dislike\" (0)\n",
    "    sentiment_cast = 0\n",
    "    # Positive polarity is cast as \"like\" (1)\n",
    "    if polarity > 0:\n",
    "        sentiment_cast = 1\n",
    "\n",
    "    textblob_sentiments.append(sentiment_cast)\n",
    "\n",
    "pearson_corr_coeff = np.corrcoef(textblob_sentiments, liked_column)\n",
    "print(\"Pearson correlation coefficient matrix:\\n\", pearson_corr_coeff)\n",
    "print(\"\\nPearson correlation between textblob sentiment and review liked score:\\n\", pearson_corr_coeff[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall cosine similarity: 0.22280560449481546\n",
      "Positive cosine similarity: 0.12447903224391887\n",
      "Negative cosine similarity: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\scipy\\spatial\\distance.py:620: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 2.\n",
    "Repeat 1) when using the cosine similarity measure. Repeat this process when considering the correlation of the positive\n",
    "class alone and the correlation of the negative class alone.\n",
    "\"\"\"\n",
    "\n",
    "# Calculate overall coseine similarity\n",
    "cosine_similarity = cosine(textblob_sentiments, liked_column)\n",
    "print(\"Overall cosine similarity:\", cosine_similarity)\n",
    "\n",
    "\n",
    "# Calculate cosine similarity of positive class alone\n",
    "positive_textblob_sentiments = []\n",
    "positive_corresponding_liked_column = []\n",
    "\n",
    "for index, rating in enumerate(textblob_sentiments):\n",
    "    if rating == 1:\n",
    "        positive_textblob_sentiments.append(textblob_sentiments[index])\n",
    "        positive_corresponding_liked_column.append(liked_column[index])\n",
    "\n",
    "positive_cosine_similarity = cosine(positive_textblob_sentiments, positive_corresponding_liked_column)\n",
    "print(\"Positive cosine similarity:\", positive_cosine_similarity)\n",
    "\n",
    "\n",
    "# Calculate cosine similarity of negative class alone\n",
    "negative_textblob_sentiments = []\n",
    "negative_corresponding_liked_column = []\n",
    "\n",
    "for index, rating in enumerate(textblob_sentiments):\n",
    "    if rating == 0:\n",
    "        negative_textblob_sentiments.append(textblob_sentiments[index])\n",
    "        negative_corresponding_liked_column.append(liked_column[index])\n",
    "\n",
    "# Undefined, division with 0 happens when one of the vectors of cosine similarity is all zeroes\n",
    "negative_cosine_similarity = cosine(negative_textblob_sentiments, negative_corresponding_liked_column)\n",
    "print(\"Negative cosine similarity:\", negative_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between review length and review liked score:\n",
      " -0.07528475029141278\n",
      "\n",
      "Cosine similarity between review length and review liked score:\n",
      " 0.4074577663796183\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 3.\n",
    "Now we want to test the correlation with respect to some stylistic aspects of the review. Write a script that estimate\n",
    "the length of the review in terms of number of characters. Compute both the Pearson correlation and the cosine similarity\n",
    "between the Review length and the annotations.\n",
    "\"\"\"\n",
    "\n",
    "# Add review_length column to dataframe\n",
    "reviews_df['review_length']  = reviews_df['Review'].str.len()\n",
    "review_length_column = reviews_df[\"review_length\"]\n",
    "\n",
    "# Calculate Pearson correlation between review length and review liked score\n",
    "pearson_corr_coeff_length = np.corrcoef(review_length_column, liked_column)\n",
    "print(\"Pearson correlation between review length and review liked score:\\n\", pearson_corr_coeff_length[1][0])\n",
    "\n",
    "# Calculate cosine similarity between review length and review liked score\n",
    "cosine_similarity_length = cosine(review_length_column, liked_column)\n",
    "print(\"\\nCosine similarity between review length and review liked score:\\n\", cosine_similarity_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 4.\n",
    "We want to test the hypothesis that the opinion of about the restaurant is constructed according to Price, Quality of\n",
    "food, Quantity of the food, and location of restaurant. Suggest a script that allows you to identify Review that are\n",
    "more focused on price, quality of food, quantity of food and location of restaurant. You may consider a set of keywords\n",
    "that are most suitable to each category and then use simple string matching to match this effect. For each category,\n",
    "generate a binary vector indicating whether the given review focuses on the corresponding category.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 5.\n",
    "Estimate the correlation using Pearson correlation and cosine similarity between each vector category and the data annotation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 6.\n",
    "We want to revisit the construction of the categories in 4). Instead of string matching, use the semantic similarity in\n",
    "the following way. Calculate the Wu and Palmer similarity between “price” and the Review (using the sentence-to-sentence\n",
    "similarity as in labs), repeat this process for the other three categories by suggestion a representative keyword (s)\n",
    "that will be used to calculate sentence-to-sentence similarity score.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 7.\n",
    "We want to test another approach for computing the categories by using the empath categories embedding. For this\n",
    "purpose, re-visit the naming of the empath-categories in GitHub - Ejhfast/empath- client: analyze text with empath and\n",
    "select those that might be linked to Price, Quality, Quantity, Location. Write a code that allows you to determine\n",
    "appropriate categories from this embedding and then calculate the correlation score. Alternative to manual scrutinization\n",
    "of the Empath categories, you may also generate an empath category embedding for the keyword “price”, “food quality”,\n",
    "“food quantity”, “location” and then compute cosine similarity between the Review embedding vector and each of the above\n",
    "four embedding vectors, so that the one that yields the highest similarity score will be considered as the one that best\n",
    "represents the underlined category.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 8.\n",
    "Repeat the 1-7) when using SentiStrength sentiment analyzer instead of textblob.\n",
    "The package is available from sentistrength.wlv.ac.uk.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 9.\n",
    "We want to further emphasize on misclassified reviews. For this purpose, concatenate all reviews for which the\n",
    "sentiment score is positive while the annotation is zero and those for which the sentiment is zero while the annotation\n",
    "is 1. Construct the Wordcloud of this dataset. Write a histogram showing the 10 most common wordings in this dataset.\n",
    "Comment on the findings.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 10.\n",
    "Now we would like to build a machine learning model for sentiment analysis that takes into account the ambiguous cases\n",
    "identified in 9). For this purpose, write and script and review the preprocessing and stopword list to not discard\n",
    "relevant information in the context of sentiment analysis (e.g., avoid discarding negation cues, adjectives that\n",
    "subsumes polarity and apostrophes, lower-case as capitalization brings emotion,..), then use TfIdfVectorizer with a\n",
    "maximum feature set of 1000, minimum 2 repetition and no more than 60% of word repetition across sentences. Build this\n",
    "model for one dataset using randomly selected 70% training and 30% testing. Report the classification accuracy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 11.\n",
    "Use FastText encoding instead of TfidfVectorizer, see https://github.com/facebookresearch/fastText/archive/v0.2.0.zip\n",
    "You should install Fasttext and consult one of the tutorial to find out how you will run it, see, e.g., FastText Word\n",
    "Embeddings Python implementation - ThinkInfi. Use the FastText embedding as feature vectors and test the performance\n",
    "in the original data (30% test data) and report the classification accuracy on the other two datasets. Comment on the\n",
    "limitations of the approach\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
